{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + ANN Baseline\n",
    "* Reference paper: https://jfin-swufe.springeropen.com/track/pdf/10.1186/s40854-019-0138-0.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import torch.utils.data as Data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv('data/Processed_S&P.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df['Date'] = pd.to_datetime(base_df['Date'], format='%Y-%m-%d')\n",
    "base_df.sort_values(by='Date', inplace=True)\n",
    "base_df.drop(columns=['Name', 'Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outliers\n",
    "for col in base_df.columns:\n",
    "    q1, q3 = base_df[col].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lb, rb = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    for i in range(len(base_df)):\n",
    "        if base_df[col][i] > rb:\n",
    "            base_df[col][i] = rb\n",
    "        if base_df[col][i] < lb:\n",
    "            base_df[col][i] = lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "* PCA with n_components = 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketDataset(Data.Dataset):\n",
    "    DATA_PATH = 'data/Processed_S&P.csv'\n",
    "    TRAIN_RATIO = 0.7\n",
    "    VALIDATION_RATIO = 0.15\n",
    "    TEST_RATIO = 0.15\n",
    "\n",
    "    def __init__(self, test=False, train_ds=None):\n",
    "        global base_df\n",
    "        if test:\n",
    "            df = base_df.iloc[int((1 - MarketDataset.TEST_RATIO) * len(base_df)):]\n",
    "            assert (train_ds is not None)\n",
    "            df = (df - train_ds.mean) / train_ds.std\n",
    "            self.X = train_ds.pca.transform(df)\n",
    "        else:\n",
    "            df = base_df.iloc[:int((1 - MarketDataset.TEST_RATIO) * len(base_df))]\n",
    "            self.mean = df.mean()\n",
    "            self.std = df.std()\n",
    "            df = (df - self.mean) / self.std\n",
    "            self.pca = PCA()\n",
    "            self.pca.fit(df)\n",
    "            self.X = self.pca.transform(df)\n",
    "            self.train_len = int((MarketDataset.TRAIN_RATIO * len(df)) / (MarketDataset.TRAIN_RATIO + MarketDataset.VALIDATION_RATIO))\n",
    "            self.validation_len = len(df) - self.train_len - 1\n",
    "            self.validation_range = range(self.train_len + 1, self.train_len + self.validation_len)\n",
    "\n",
    "        self.X = torch.tensor(self.X).float()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def get_label(self, idx):\n",
    "        return torch.tensor([float(self.df['Close'][idx + 1] > self.df['Close'][idx])])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.get_label(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - 1\n",
    "    \n",
    "\n",
    "train_ds = MarketDataset(test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(82, 41),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(41, 20),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ---\n",
      "Training loss: 0.5723672087185461\n",
      "Accuracy: 0.5180115273775217\n",
      "F-score: 0.5962582981291491\n",
      "Epoch 2 ---\n",
      "Training loss: 0.5662601844847025\n",
      "Accuracy: 0.5324207492795389\n",
      "F-score: 0.6673500768836494\n",
      "Epoch 3 ---\n",
      "Training loss: 0.5607976587572154\n",
      "Accuracy: 0.5612391930835735\n",
      "F-score: 0.6518010291595198\n",
      "Epoch 4 ---\n",
      "Training loss: 0.5596082985401154\n",
      "Accuracy: 0.5857348703170029\n",
      "F-score: 0.6859639541234298\n",
      "Validation accuracy: 0.5304054054054054\n",
      "Epoch 5 ---\n",
      "Training loss: 0.5450985162831202\n",
      "Accuracy: 0.6001440922190202\n",
      "F-score: 0.6790052053209948\n",
      "Epoch 6 ---\n",
      "Training loss: 0.5392789073310549\n",
      "Accuracy: 0.6260806916426513\n",
      "F-score: 0.6916221033868094\n",
      "Epoch 7 ---\n",
      "Training loss: 0.5282102182971794\n",
      "Accuracy: 0.6311239193083573\n",
      "F-score: 0.6893203883495146\n",
      "Epoch 8 ---\n",
      "Training loss: 0.5059435451077159\n",
      "Accuracy: 0.6693083573487032\n",
      "F-score: 0.7209726443768998\n",
      "Validation accuracy: 0.5405405405405406\n",
      "Epoch 9 ---\n",
      "Training loss: 0.506416118106299\n",
      "Accuracy: 0.6621037463976945\n",
      "F-score: 0.7131498470948012\n",
      "Epoch 10 ---\n",
      "Training loss: 0.4920541606871107\n",
      "Accuracy: 0.6851585014409222\n",
      "F-score: 0.7314074984634296\n",
      "Epoch 11 ---\n",
      "Training loss: 0.4820266717482491\n",
      "Accuracy: 0.702449567723343\n",
      "F-score: 0.7410658307210032\n",
      "Epoch 12 ---\n",
      "Training loss: 0.48223886651509285\n",
      "Accuracy: 0.6858789625360231\n",
      "F-score: 0.7254408060453401\n",
      "Validation accuracy: 0.5675675675675675\n",
      "Epoch 13 ---\n",
      "Training loss: 0.47699082932401815\n",
      "Accuracy: 0.7038904899135446\n",
      "F-score: 0.7473878303626306\n",
      "Epoch 14 ---\n",
      "Training loss: 0.4603696831036359\n",
      "Accuracy: 0.7190201729106628\n",
      "F-score: 0.7540983606557378\n",
      "Epoch 15 ---\n",
      "Training loss: 0.44860986813181564\n",
      "Accuracy: 0.723342939481268\n",
      "F-score: 0.7611940298507462\n",
      "Epoch 16 ---\n",
      "Training loss: 0.4518935937818571\n",
      "Accuracy: 0.7298270893371758\n",
      "F-score: 0.7654784240150094\n",
      "Validation accuracy: 0.5878378378378378\n",
      "Epoch 17 ---\n",
      "Training loss: 0.4272393249095838\n",
      "Accuracy: 0.7319884726224783\n",
      "F-score: 0.7633587786259542\n",
      "Epoch 18 ---\n",
      "Training loss: 0.42105924613419393\n",
      "Accuracy: 0.7456772334293948\n",
      "F-score: 0.7753023551877786\n",
      "Epoch 19 ---\n",
      "Training loss: 0.42988556175575093\n",
      "Accuracy: 0.7435158501440923\n",
      "F-score: 0.772378516624041\n",
      "Epoch 20 ---\n",
      "Training loss: 0.4206811912435921\n",
      "Accuracy: 0.7572046109510087\n",
      "F-score: 0.7852135117909496\n",
      "Validation accuracy: 0.543918918918919\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "validation_interval = 4\n",
    "validation_accuracies = []\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "train_f_scores = []\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    running_loss = 0\n",
    "    labels = []\n",
    "    predicted = []\n",
    "    for i in range(train_ds.train_len):\n",
    "        X, Y = train_ds[i]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(X)\n",
    "        labels.append(int(output[0] >= 0.5))\n",
    "        predicted.append(int(Y[0]))\n",
    "        loss = criterion(output, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    train_acc = metrics.accuracy_score(labels, predicted)\n",
    "    f_score = metrics.f1_score(labels, predicted)\n",
    "    running_loss /= len(train_ds)\n",
    "\n",
    "    print(f'Epoch {e} ---')\n",
    "    print(f'Training loss: {running_loss}')\n",
    "    print(f'Accuracy: {train_acc}') \n",
    "    print(f'F-score: {f_score}')\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    train_f_scores.append(f_score)\n",
    "    train_losses.append(running_loss)\n",
    "\n",
    "    if e % validation_interval == 0:\n",
    "        model.eval()\n",
    "        labels = []\n",
    "        predicted = []\n",
    "        for i in train_ds.validation_range:\n",
    "            X, Y = train_ds[i]\n",
    "            with torch.no_grad():\n",
    "                labels.append(int(model(X)[0] >= 0.5))\n",
    "            predicted.append(int(Y[0]))\n",
    "        validation_acc = metrics.accuracy_score(labels, predicted)\n",
    "        print(f'Validation accuracy: {validation_acc}')\n",
    "        validation_accuracies.append(validation_acc)\n",
    "        model.train()\n",
    "        if len(validation_accuracies) > 1 and validation_accuracies[-1] < validation_accuracies[-2]:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = MarketDataset(test=True, train_ds=train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5723905723905723\n",
      "F-score on test set: 0.6894865525672371\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_labels = []\n",
    "test_predicted = []\n",
    "for i in range(len(test_ds)):\n",
    "    X, Y = test_ds[i]\n",
    "    with torch.no_grad():\n",
    "        test_labels.append(int(model(X)[0] >= 0.5))\n",
    "    test_predicted.append(int(Y[0]))\n",
    "print(f'Test accuracy: {metrics.accuracy_score(test_labels, test_predicted)}')\n",
    "print(f'F-score on test set: {metrics.f1_score(test_labels, test_predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model-params.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
