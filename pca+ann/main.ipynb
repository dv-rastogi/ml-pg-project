{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + ANN Baseline\n",
    "* Reference paper: https://jfin-swufe.springeropen.com/track/pdf/10.1186/s40854-019-0138-0.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.utils.data as Data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_columns', 500)\n",
    "DATA_PATH = '../data/Processed_S&P.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df['Date'] = pd.to_datetime(base_df['Date'], format='%Y-%m-%d')\n",
    "base_df.sort_values(by='Date', inplace=True)\n",
    "base_df.drop(columns=['Name', 'Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outliers\n",
    "for col in base_df.columns:\n",
    "    q1, q3 = base_df[col].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lb, rb = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    for i in range(len(base_df)):\n",
    "        if base_df[col][i] > rb:\n",
    "            base_df[col][i] = rb\n",
    "        if base_df[col][i] < lb:\n",
    "            base_df[col][i] = lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "* PCA with n_components = 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketDataset(Data.Dataset):\n",
    "    TRAIN_RATIO = 0.7\n",
    "    TEST_RATIO = 0.15\n",
    "\n",
    "    def __init__(self, type, train_ds=None):\n",
    "        global base_df\n",
    "        n = len(base_df)\n",
    "        if type == 'Test':\n",
    "            df = base_df.iloc[int((1 - MarketDataset.TEST_RATIO) * n):]\n",
    "            assert (train_ds is not None)\n",
    "            df = (df - train_ds.mean) / train_ds.std\n",
    "            self.X = train_ds.pca.transform(df)\n",
    "        elif type == 'Train':\n",
    "            df = base_df.iloc[:int(MarketDataset.TRAIN_RATIO * n)]\n",
    "            self.mean = df.mean()\n",
    "            self.std = df.std()\n",
    "            df = (df - self.mean) / self.std\n",
    "            self.pca = PCA()\n",
    "            self.pca.fit(df)\n",
    "            self.X = self.pca.transform(df)\n",
    "        elif type == 'Validation':            \n",
    "            df = df = base_df.iloc[int(MarketDataset.TRAIN_RATIO * n): int((1 - MarketDataset.TEST_RATIO) * n)]\n",
    "            assert (train_ds is not None)\n",
    "            df = (df - train_ds.mean) / train_ds.std\n",
    "            self.X = train_ds.pca.transform(df)\n",
    "            \n",
    "        self.X = torch.tensor(self.X).float()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def get_label(self, idx):\n",
    "        return torch.tensor([float(self.df['Close'][idx + 1] > self.df['Close'][idx])])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.get_label(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MarketDataset(type='Train')\n",
    "validation_ds = MarketDataset(type='Validation', train_ds=train_ds)\n",
    "test_ds = MarketDataset(type='Test', train_ds=train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(82, 41),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(41, 20),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ---\n",
      "Training loss: 0.716026068464319\n",
      "Accuracy: 0.44844989185291995\n",
      "F-score: 0.0\n",
      "Epoch 2 ---\n",
      "Training loss: 0.7081766309889427\n",
      "Accuracy: 0.44844989185291995\n",
      "F-score: 0.0\n",
      "Epoch 3 ---\n",
      "Training loss: 0.7032327764568865\n",
      "Accuracy: 0.44844989185291995\n",
      "F-score: 0.0\n",
      "Validation accuracy: 0.49158249158249157\n",
      "Epoch 4 ---\n",
      "Training loss: 0.699156136631364\n",
      "Accuracy: 0.44844989185291995\n",
      "F-score: 0.0\n",
      "Epoch 5 ---\n",
      "Training loss: 0.6951162109464385\n",
      "Accuracy: 0.45061283345349673\n",
      "F-score: 0.16447368421052633\n",
      "Epoch 6 ---\n",
      "Training loss: 0.6917639121617356\n",
      "Accuracy: 0.5212689257390051\n",
      "F-score: 0.5931372549019608\n",
      "Validation accuracy: 0.5151515151515151\n",
      "Epoch 7 ---\n",
      "Training loss: 0.6899514470757042\n",
      "Accuracy: 0.5508291276135544\n",
      "F-score: 0.6977195536147501\n",
      "Epoch 8 ---\n",
      "Training loss: 0.6875285067271224\n",
      "Accuracy: 0.5508291276135544\n",
      "F-score: 0.7092860475968268\n",
      "Epoch 9 ---\n",
      "Training loss: 0.687465221807092\n",
      "Accuracy: 0.5508291276135544\n",
      "F-score: 0.710367271036727\n",
      "Validation accuracy: 0.5084175084175084\n",
      "Epoch 10 ---\n",
      "Training loss: 0.6856470862437085\n",
      "Accuracy: 0.55155010814708\n",
      "F-score: 0.7109665427509294\n",
      "Epoch 11 ---\n",
      "Training loss: 0.6864220181341728\n",
      "Accuracy: 0.5522710886806056\n",
      "F-score: 0.7112970711297071\n",
      "Epoch 12 ---\n",
      "Training loss: 0.682413880139181\n",
      "Accuracy: 0.55155010814708\n",
      "F-score: 0.7109665427509294\n",
      "Validation accuracy: 0.5084175084175084\n",
      "Epoch 13 ---\n",
      "Training loss: 0.6811456568351132\n",
      "Accuracy: 0.55155010814708\n",
      "F-score: 0.7109665427509294\n",
      "Epoch 14 ---\n",
      "Training loss: 0.679356774023822\n",
      "Accuracy: 0.5508291276135544\n",
      "F-score: 0.710367271036727\n",
      "Epoch 15 ---\n",
      "Training loss: 0.6790493969424818\n",
      "Accuracy: 0.55155010814708\n",
      "F-score: 0.7106976744186047\n",
      "Validation accuracy: 0.5084175084175084\n",
      "Epoch 16 ---\n",
      "Training loss: 0.6799451560963807\n",
      "Accuracy: 0.55155010814708\n",
      "F-score: 0.7098880597014925\n",
      "Epoch 17 ---\n",
      "Training loss: 0.6760046466830487\n",
      "Accuracy: 0.5558759913482336\n",
      "F-score: 0.7110694183864915\n",
      "Epoch 18 ---\n",
      "Training loss: 0.6772654650876568\n",
      "Accuracy: 0.555155010814708\n",
      "F-score: 0.7071665875652587\n",
      "Validation accuracy: 0.5151515151515151\n",
      "Epoch 19 ---\n",
      "Training loss: 0.6745168434129658\n",
      "Accuracy: 0.5602018745493872\n",
      "F-score: 0.7078544061302682\n",
      "Epoch 20 ---\n",
      "Training loss: 0.6740212476481271\n",
      "Accuracy: 0.5645277577505408\n",
      "F-score: 0.7053658536585365\n",
      "Epoch 21 ---\n",
      "Training loss: 0.6689923294022861\n",
      "Accuracy: 0.5919250180245134\n",
      "F-score: 0.7192460317460317\n",
      "Validation accuracy: 0.5488215488215489\n",
      "Epoch 22 ---\n",
      "Training loss: 0.6655544634336349\n",
      "Accuracy: 0.5868781542898341\n",
      "F-score: 0.7083969465648855\n",
      "Epoch 23 ---\n",
      "Training loss: 0.6655753134671268\n",
      "Accuracy: 0.6049026676279741\n",
      "F-score: 0.7189743589743589\n",
      "Epoch 24 ---\n",
      "Training loss: 0.6686881437962143\n",
      "Accuracy: 0.5919250180245134\n",
      "F-score: 0.7002118644067796\n",
      "Validation accuracy: 0.5656565656565656\n",
      "Epoch 25 ---\n",
      "Training loss: 0.663228642472107\n",
      "Accuracy: 0.6027397260273972\n",
      "F-score: 0.7023230686115614\n",
      "Epoch 26 ---\n",
      "Training loss: 0.6611584009738302\n",
      "Accuracy: 0.6200432588320115\n",
      "F-score: 0.7109160724081185\n",
      "Epoch 27 ---\n",
      "Training loss: 0.6595646767368742\n",
      "Accuracy: 0.619322278298486\n",
      "F-score: 0.707641196013289\n",
      "Validation accuracy: 0.5185185185185185\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "validation_interval = 3\n",
    "validation_accuracies = []\n",
    "previous_model_state = {}\n",
    "early_stopping_threshold = 0.015\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "train_f_scores = []\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    running_loss = 0\n",
    "    labels = []\n",
    "    predicted = []\n",
    "    for i in range(len(train_ds)):\n",
    "        X, Y = train_ds[i]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(X)\n",
    "        predicted.append(int(output[0] >= 0.5))\n",
    "        labels.append(int(Y[0]))\n",
    "        loss = criterion(output, Y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_acc = metrics.accuracy_score(labels, predicted)\n",
    "    f_score = metrics.f1_score(labels, predicted)\n",
    "    running_loss /= len(train_ds)\n",
    "\n",
    "    print(f'Epoch {e} ---')\n",
    "    print(f'Training loss: {running_loss}')\n",
    "    print(f'Accuracy: {train_acc}') \n",
    "    print(f'F-score: {f_score}')\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    train_f_scores.append(f_score)\n",
    "    train_losses.append(running_loss)\n",
    "\n",
    "    if e % validation_interval == 0:\n",
    "        model.eval()\n",
    "        labels = []\n",
    "        predicted = []\n",
    "        validation_loss = 0\n",
    "        for i in range(len(validation_ds)):\n",
    "            X, Y = validation_ds[i]\n",
    "            with torch.no_grad():\n",
    "                predicted.append(int(model(X)[0] >= 0.5))\n",
    "            labels.append(int(Y[0]))\n",
    "        validation_acc = metrics.accuracy_score(labels, predicted)\n",
    "        print(f'Validation accuracy: {validation_acc}')\n",
    "        validation_accuracies.append(validation_acc)\n",
    "        model.train()\n",
    "        if len(validation_accuracies) > 1 and (validation_accuracies[-2] - validation_accuracies[-1] >= early_stopping_threshold):\n",
    "            model.load_state_dict(previous_model_state)\n",
    "            break\n",
    "        previous_model_state = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5589225589225589\n",
      "F-score on test set: 0.7082405345211582\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_labels = []\n",
    "test_predicted = []\n",
    "for i in range(len(test_ds)):\n",
    "    X, Y = test_ds[i]\n",
    "    with torch.no_grad():\n",
    "        test_predicted.append(int(model(X)[0] >= 0.5))\n",
    "    test_labels.append(int(Y[0]))\n",
    "print(f'Test accuracy: {metrics.accuracy_score(test_labels, test_predicted)}')\n",
    "print(f'F-score on test set: {metrics.f1_score(test_labels, test_predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model-params.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
